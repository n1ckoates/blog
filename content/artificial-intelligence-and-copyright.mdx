---
title: Artificial Intelligence and the Copyright Question
date: 2023-04-18 18:00:00 -07:00
summary: Generative AIs are blowing up, but their legality from a copyright standpoint isn't yet defined.
cover: /images/blog/artificial-intelligence-and-copyright.jpg
coverAlt: An abstract grid of spheres rising and falling into a grid of circular holes beneath.
---

Generative AIs are blowing up. Ever since OpenAI launched ChatGPT back in November, it feels like every company is rushing to integrate it into their products. Microsoft [overhauled Bing](https://news.microsoft.com/the-new-Bing/) with a focus on AI, and Adobe [launched Firefly](https://www.adobe.com/sensei/generative-ai/firefly.html), all while Google -- who is normally a _leader_ in these types of things -- is trying to play catch up with [Bard](https://bard.google.com/). **The AI wars have begun**, and there doesn't seem to be a clear winner right now.

But the biggest question, one which could ultimately decide the fate of these AIs, is copyright. All of the big generative AI models are trained on copyrighted material, and whether or not that's considered fair use is still up for debate. The law is often slow to adapt, _especially_ when it comes to technology, and this is no exception. Companies have [insisted](https://twitter.com/natfriedman/status/1409914420579344385) that it's perfectly fine, but they're also the ones that stand to profit off of it.

Artists, on the other hand, have overwhelmingly opposed generative AIs -- and for good reason. Not only does it threaten their livelihood, by potentially automating and replacing their jobs, but the models themselves are trained on their work without their consent. They're understandably angry and frustrated when companies move forward with these technologies without reflecting -- or without caring -- about the implications.

---

I have no idea how this will play out, but my own personal opinion is that they should _not_ be considered fair use. Models are fundamentally different from say a human brain, because they lack any real understanding or creativity -- and at the end of the day, they're just _really_ good at guessing.

OpenAI in 2023 feels like [Napster](https://en.wikipedia.org/wiki/Napster) in 2001; even _if_ they get sued out of existence, they still set the ball rolling. And it feels like nothing can slow that down.

<NewsletterForm />
